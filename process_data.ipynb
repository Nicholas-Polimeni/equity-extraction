{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data for Equity Loss Analysis\n",
    "\n",
    "## Data Sources\n",
    "- Fulton County digest parcel data from 2011 to 2022 (selected for LUC=101, SFHs), excel\n",
    "- Fulton County digest parcel data for 2022 (for geocoding), geojson\n",
    "- Fulton County sales data from 2011 to 2022, txt\n",
    "- Atlanta Neighborhood Statistical Areas with supplemental data from Census (), 2022, csv from Neighborhood Nexus\n",
    "- Neighborhood characteristics? unknown\n",
    "\n",
    "**Note: NSAs in DeKalb are excluded, we do not have data for all years**\n",
    "\n",
    "Those neighborhoods are:\n",
    "- Candler Park, Druid Hills\n",
    "- Lake Claire\n",
    "- East Lake\n",
    "- Kirkwood\n",
    "- Edgewood\n",
    "- East Atlanta\n",
    "- Emory University/Center for Disease Control\n",
    "- Part of Morningside/Lenox Park\n",
    "\n",
    "This leaves _ neighborhoods (see appendix for list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_keyword(filename: str, keywords: list[str]) -> str:\n",
    "    return any(keyword in filename for keyword in keywords)\n",
    "\n",
    "def clean_and_cast_column(column: pd.Series, var_map: dict) -> pd.Series:\n",
    "    to_dtype = var_map[column.name]\n",
    "    fill_val = None\n",
    "    \n",
    "    if to_dtype == \"int\" or to_dtype == \"float\":\n",
    "        fill_val = 0\n",
    "    elif to_dtype == \"string\":\n",
    "        fill_val = \"\"\n",
    "    else:\n",
    "        raise ValueError(f\"{to_dtype} is not a valid data type!\")\n",
    "    \n",
    "    if ((to_dtype == \"int\" or to_dtype == \"float\")\n",
    "        and (column.dtype == \"string\" or column.dtype == \"object\")):\n",
    "        # Remove commas from number strings before converting\n",
    "        column = column.astype(\"str\").str.replace(\",\", \"\").astype('float')\n",
    "    \n",
    "    # Record number of filled nulls\n",
    "    print(f\"Number of nulls in column {column.name}: {column.isna().sum()}\")\n",
    "    column = column.fillna(fill_val)\n",
    "    return column.astype(to_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a file with Fulton County digest data for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select desired digest files\n",
    "FULTON_DIR = './data/raw_fulton/'\n",
    "fulton_files = os.listdir(FULTON_DIR)\n",
    "\n",
    "keywords = [\"DIGEST\", \"NF\", \"SF\"]\n",
    "digest_cols = {\n",
    "    \"Taxyr\": \"int\",\n",
    "    \"Parid\": \"string\",\n",
    "    \"Situs Adrno\": \"int\",\n",
    "    \"Situs Adrdir\": \"string\",\n",
    "    \"Situs Adrstr\": \"string\",\n",
    "    \"Situs Adrsuf\": \"string\",\n",
    "    \"Cityname\": \"string\",\n",
    "    \"Luc\": \"string\",\n",
    "    \"Calcacres\": \"float\",\n",
    "    \"Own1\": \"string\",\n",
    "    \"Own2\": \"string\",\n",
    "    \"Owner Adrno\": \"int\",\n",
    "    \"Owner Adradd\": \"string\",\n",
    "    \"Owner Adrdir\": \"string\",\n",
    "    \"Owner Adrstr\": \"string\",\n",
    "    \"Owner Adrsuf\": \"string\",\n",
    "    \"Cityname.1\": \"string\",\n",
    "    \"Statecode\": \"string\",\n",
    "    \"Zip1\": \"string\",\n",
    "    \"Aprtot\": \"float\",\n",
    "    \"D Yrblt\": \"int\",\n",
    "    \"D Effyr\": \"int\",\n",
    "    \"D Yrremod\": \"int\",\n",
    "    \"Sfla\": \"float\"\n",
    "}\n",
    "\n",
    "desired_files = filter(lambda file: contains_keyword(file, keywords), fulton_files)\n",
    "\n",
    "# Read desired files and only parse desired cols\n",
    "# Need to ensure Luc is read in as a str so we can filter appropriately\n",
    "desired_files_dfs = [\n",
    "    pd.read_excel(\n",
    "        FULTON_DIR + file,\n",
    "        usecols=digest_cols,\n",
    "        dtype={\"Luc\": \"str\"}\n",
    "    ) for file in desired_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat selected digest files, select for LUC = 101 (SFH), drop complete duplicates\n",
    "# Record total number of parcels\n",
    "digest_full = pd.concat(desired_files_dfs)\n",
    "digest_full = digest_full[digest_full['Luc'] == '101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init len: 3681749. Number of dropped duplicates: 896302. Final len: 2785447\n",
      "Number of nulls in column Taxyr: 0\n",
      "Number of nulls in column Parid: 0\n",
      "Number of nulls in column Situs Adrno: 45\n",
      "Number of nulls in column Situs Adrdir: 2783381\n",
      "Number of nulls in column Situs Adrstr: 22\n",
      "Number of nulls in column Situs Adrsuf: 189813\n",
      "Number of nulls in column Cityname: 4973\n",
      "Number of nulls in column Luc: 0\n",
      "Number of nulls in column Calcacres: 572\n",
      "Number of nulls in column Own1: 0\n",
      "Number of nulls in column Own2: 2331350\n",
      "Number of nulls in column Owner Adrno: 67785\n",
      "Number of nulls in column Owner Adradd: 2780418\n",
      "Number of nulls in column Owner Adrdir: 2723376\n",
      "Number of nulls in column Owner Adrstr: 3572\n",
      "Number of nulls in column Owner Adrsuf: 213850\n",
      "Number of nulls in column Cityname.1: 3167\n",
      "Number of nulls in column Statecode: 3482\n",
      "Number of nulls in column Zip1: 4131\n",
      "Number of nulls in column Aprtot: 0\n",
      "Number of nulls in column D Yrblt: 3899\n",
      "Number of nulls in column D Effyr: 2262400\n",
      "Number of nulls in column D Yrremod: 2659408\n",
      "Number of nulls in column Sfla: 3875\n"
     ]
    }
   ],
   "source": [
    "# After filtering for Luc, we can continue to cast other columns\n",
    "rename = {\n",
    "    \"Taxyr\": \"TAXYR\",\n",
    "    \"Parid\": \"PARID\",\n",
    "    \"Cityname.1\": \"own_cityname\",\n",
    "    \"Zip1\": \"own_zip\"\n",
    "}\n",
    "init_len = len(digest_full)\n",
    "\n",
    "digest_full = digest_full.drop_duplicates()\n",
    "print(f\"Init len: {init_len}. Number of dropped duplicates: {init_len - len(digest_full)}. Final len: {len(digest_full)}\")\n",
    "\n",
    "# Records nulls and set datatypes\n",
    "for column in digest_full.columns:\n",
    "    digest_full[column] = clean_and_cast_column(digest_full[column], digest_cols)\n",
    "    \n",
    "digest_full = digest_full.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAXYR</th>\n",
       "      <th>PARID</th>\n",
       "      <th>Situs Adrno</th>\n",
       "      <th>Situs Adrdir</th>\n",
       "      <th>Situs Adrstr</th>\n",
       "      <th>Situs Adrsuf</th>\n",
       "      <th>Cityname</th>\n",
       "      <th>Luc</th>\n",
       "      <th>Calcacres</th>\n",
       "      <th>Own1</th>\n",
       "      <th>Own2</th>\n",
       "      <th>Owner Adrno</th>\n",
       "      <th>Owner Adradd</th>\n",
       "      <th>Owner Adrdir</th>\n",
       "      <th>Owner Adrstr</th>\n",
       "      <th>Owner Adrsuf</th>\n",
       "      <th>own_cityname</th>\n",
       "      <th>Statecode</th>\n",
       "      <th>own_zip</th>\n",
       "      <th>Aprtot</th>\n",
       "      <th>D Yrblt</th>\n",
       "      <th>D Effyr</th>\n",
       "      <th>D Yrremod</th>\n",
       "      <th>Sfla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61038</th>\n",
       "      <td>2015</td>\n",
       "      <td>14F007900030370</td>\n",
       "      <td>1410</td>\n",
       "      <td></td>\n",
       "      <td>MARTINIQUE</td>\n",
       "      <td>CT</td>\n",
       "      <td>FUL</td>\n",
       "      <td>101</td>\n",
       "      <td>0.58</td>\n",
       "      <td>FERNANDES RITA E</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P.O. BOX 311609</td>\n",
       "      <td></td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>31131</td>\n",
       "      <td>91700.00</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1553.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34601</th>\n",
       "      <td>2014</td>\n",
       "      <td>14 008600060473</td>\n",
       "      <td>553</td>\n",
       "      <td></td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>ST</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>101</td>\n",
       "      <td>0.06</td>\n",
       "      <td>SHAODONG LIU</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40000.00</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1320.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83901</th>\n",
       "      <td>2013</td>\n",
       "      <td>14 010700060593</td>\n",
       "      <td>826</td>\n",
       "      <td></td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ST</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>101</td>\n",
       "      <td>0.17</td>\n",
       "      <td>PRECISION INVESTMENT PROPERTIES LLC</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>P.O. BOX 366512</td>\n",
       "      <td></td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>30336</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TAXYR            PARID  Situs Adrno Situs Adrdir Situs Adrstr  \\\n",
       "61038   2015  14F007900030370         1410                MARTINIQUE   \n",
       "34601   2014  14 008600060473          553                    MIDDLE   \n",
       "83901   2013  14 010700060593          826                     WHITE   \n",
       "\n",
       "      Situs Adrsuf Cityname  Luc  Calcacres  \\\n",
       "61038           CT      FUL  101       0.58   \n",
       "34601           ST  ATLANTA  101       0.06   \n",
       "83901           ST  ATLANTA  101       0.17   \n",
       "\n",
       "                                      Own1 Own2  Owner Adrno Owner Adradd  \\\n",
       "61038                     FERNANDES RITA E                 0                \n",
       "34601                         SHAODONG LIU                 0                \n",
       "83901  PRECISION INVESTMENT PROPERTIES LLC                 0                \n",
       "\n",
       "      Owner Adrdir     Owner Adrstr Owner Adrsuf own_cityname Statecode  \\\n",
       "61038               P.O. BOX 311609                   ATLANTA        GA   \n",
       "34601                                                                     \n",
       "83901               P.O. BOX 366512                   ATLANTA        GA   \n",
       "\n",
       "      own_zip   Aprtot  D Yrblt  D Effyr  D Yrremod    Sfla  \n",
       "61038   31131 91700.00     1991        0          0 1553.00  \n",
       "34601         40000.00     2004        0          0 1320.00  \n",
       "83901   30336 25000.00     2005        0          0 1830.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digest_full[digest_full['Owner Adrno'] == 0].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: cases where Owner Adrno is empty is often because it is a PO BOX in the Owner Adrstr column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2785447, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TAXYR\n",
       "2010    208196\n",
       "2011    208421\n",
       "2012    208964\n",
       "2013    209749\n",
       "2014    210860\n",
       "2015    212335\n",
       "2016    202821\n",
       "2017    216088\n",
       "2018    217793\n",
       "2019    219790\n",
       "2020    222101\n",
       "2021    223659\n",
       "2022    224670\n",
       "Name: PARID, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly validate no data quality issues by looking at number of parcels per year\n",
    "print(digest_full.shape)\n",
    "digest_full.groupby(\"TAXYR\")['PARID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It looks like a few parcels are lost between 2015 and 2016 (approx 10K) - this is potentially a flaw in Fulton data, not our own processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV, Parquet\n",
    "OUTPUT_PATH = 'output/fulton_parcels_all'\n",
    "digest_full.to_csv(OUTPUT_PATH + '.csv', index=False)\n",
    "digest_full.to_parquet(OUTPUT_PATH + '.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a file with Fulton County sales data for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\1391998345.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Select desired sales files\n",
    "keywords = [\"STANDARDS SALES\"]\n",
    "sale_cols = {\n",
    "    \"Taxyr\": \"int\",\n",
    "    \"Parid\": \"string\",\n",
    "    \"Saledt\": \"string\",\n",
    "    \"Luc\": \"string\",\n",
    "    \"SALES PRICE\": \"float\",\n",
    "    \"FAIR MARKET VALUE\": \"float\",\n",
    "    \"DEED TYPE\": \"string\",\n",
    "    \"Saleval\": \"string\",\n",
    "    \"Costval\": \"string\",\n",
    "    \"GRANTOR\": \"string\",\n",
    "    \"GRANTEE\": \"string\",\n",
    "}\n",
    "\n",
    "desired_files = filter(lambda file: contains_keyword(file, keywords), fulton_files)\n",
    "\n",
    "desired_files_dfs = [\n",
    "    pd.read_csv(\n",
    "        FULTON_DIR + file,\n",
    "        sep='\\t',\n",
    "        encoding='latin-1',\n",
    "        usecols=sale_cols,\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        skipfooter=1,\n",
    "        on_bad_lines=\"warn\"\n",
    "    ) for file in desired_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init len: 275814. Number of dropped duplicates: 461\n",
      "Number of nulls in column Taxyr: 0\n",
      "Number of nulls in column Parid: 0\n",
      "Number of nulls in column Luc: 0\n",
      "Number of nulls in column Saledt: 0\n",
      "Number of nulls in column SALES PRICE: 19\n",
      "Number of nulls in column FAIR MARKET VALUE: 0\n",
      "Number of nulls in column DEED TYPE: 2\n",
      "Number of nulls in column Costval: 0\n",
      "Number of nulls in column Saleval: 118\n",
      "Number of nulls in column GRANTOR: 18\n",
      "Number of nulls in column GRANTEE: 8\n"
     ]
    }
   ],
   "source": [
    "# Concat selected digest files, select for LUC = 101 (SFH), drop complete duplicates\n",
    "# Record total number of sales\n",
    "rename = {\n",
    "    \"Taxyr\": \"TAXYR\",\n",
    "    \"Parid\": \"PARID\",\n",
    "}\n",
    "\n",
    "sales_full = pd.concat(desired_files_dfs)\n",
    "sales_full = sales_full[sales_full['Luc'] == '101']\n",
    "\n",
    "init_len = len(sales_full)\n",
    "sales_full = sales_full.drop_duplicates()\n",
    "print(f\"Init len: {init_len}. Number of dropped duplicates: {init_len - len(sales_full)}\")\n",
    "\n",
    "# Records nulls and set datatypes\n",
    "for column in sales_full.columns:\n",
    "    sales_full[column] = clean_and_cast_column(sales_full[column], sale_cols)\n",
    "    \n",
    "sales_full = sales_full.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TAXYR\n",
       "2011    26777\n",
       "2012    22684\n",
       "2013    26074\n",
       "2014    11711\n",
       "2015    11256\n",
       "2016    14978\n",
       "2017    13210\n",
       "2018    28281\n",
       "2019    29134\n",
       "2020    29570\n",
       "2021    28645\n",
       "2022    33033\n",
       "Name: PARID, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of data for quick validation\n",
    "sales_full.groupby(\"TAXYR\")['PARID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">SALES PRICE</th>\n",
       "      <th colspan=\"8\" halign=\"left\">FAIR MARKET VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAXYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>26777.00</td>\n",
       "      <td>162950.94</td>\n",
       "      <td>630129.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56050.00</td>\n",
       "      <td>189900.00</td>\n",
       "      <td>51718108.00</td>\n",
       "      <td>26777.00</td>\n",
       "      <td>210525.70</td>\n",
       "      <td>292278.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42100.00</td>\n",
       "      <td>115300.00</td>\n",
       "      <td>276200.00</td>\n",
       "      <td>8750000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>22684.00</td>\n",
       "      <td>164550.67</td>\n",
       "      <td>424239.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49500.00</td>\n",
       "      <td>200515.00</td>\n",
       "      <td>20500000.00</td>\n",
       "      <td>22684.00</td>\n",
       "      <td>241854.35</td>\n",
       "      <td>325947.29</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>56600.00</td>\n",
       "      <td>142800.00</td>\n",
       "      <td>314800.00</td>\n",
       "      <td>13698600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>26074.00</td>\n",
       "      <td>166081.78</td>\n",
       "      <td>440832.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47000.00</td>\n",
       "      <td>212000.00</td>\n",
       "      <td>17038094.00</td>\n",
       "      <td>26074.00</td>\n",
       "      <td>238072.86</td>\n",
       "      <td>323868.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39500.00</td>\n",
       "      <td>142225.00</td>\n",
       "      <td>325900.00</td>\n",
       "      <td>6322800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>11711.00</td>\n",
       "      <td>331640.54</td>\n",
       "      <td>351925.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>79000.00</td>\n",
       "      <td>255000.00</td>\n",
       "      <td>455000.00</td>\n",
       "      <td>6350000.00</td>\n",
       "      <td>11711.00</td>\n",
       "      <td>294653.60</td>\n",
       "      <td>320690.06</td>\n",
       "      <td>100.00</td>\n",
       "      <td>63900.00</td>\n",
       "      <td>226960.00</td>\n",
       "      <td>402150.00</td>\n",
       "      <td>6189700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>11256.00</td>\n",
       "      <td>357182.81</td>\n",
       "      <td>392959.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101425.00</td>\n",
       "      <td>275000.00</td>\n",
       "      <td>475000.00</td>\n",
       "      <td>13914719.00</td>\n",
       "      <td>11256.00</td>\n",
       "      <td>314046.58</td>\n",
       "      <td>324030.38</td>\n",
       "      <td>1390.00</td>\n",
       "      <td>74887.50</td>\n",
       "      <td>244970.00</td>\n",
       "      <td>428770.00</td>\n",
       "      <td>6151600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>14978.00</td>\n",
       "      <td>348266.13</td>\n",
       "      <td>401923.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85000.00</td>\n",
       "      <td>258325.00</td>\n",
       "      <td>474500.00</td>\n",
       "      <td>17455046.00</td>\n",
       "      <td>14978.00</td>\n",
       "      <td>346104.72</td>\n",
       "      <td>368631.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91500.00</td>\n",
       "      <td>257500.00</td>\n",
       "      <td>470000.00</td>\n",
       "      <td>6000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>13210.00</td>\n",
       "      <td>386344.64</td>\n",
       "      <td>386724.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>139000.00</td>\n",
       "      <td>294000.00</td>\n",
       "      <td>517500.00</td>\n",
       "      <td>7200000.00</td>\n",
       "      <td>13210.00</td>\n",
       "      <td>306637.00</td>\n",
       "      <td>320307.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75725.00</td>\n",
       "      <td>225900.00</td>\n",
       "      <td>425000.00</td>\n",
       "      <td>6000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>28281.00</td>\n",
       "      <td>268587.37</td>\n",
       "      <td>931256.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>108000.00</td>\n",
       "      <td>360000.00</td>\n",
       "      <td>135635876.00</td>\n",
       "      <td>28281.00</td>\n",
       "      <td>307217.92</td>\n",
       "      <td>359431.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75800.00</td>\n",
       "      <td>198500.00</td>\n",
       "      <td>418000.00</td>\n",
       "      <td>7150000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>29134.00</td>\n",
       "      <td>522038.36</td>\n",
       "      <td>2227323.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>137000.00</td>\n",
       "      <td>379900.00</td>\n",
       "      <td>40120000.00</td>\n",
       "      <td>29134.00</td>\n",
       "      <td>328591.65</td>\n",
       "      <td>367677.75</td>\n",
       "      <td>100.00</td>\n",
       "      <td>107200.00</td>\n",
       "      <td>207000.00</td>\n",
       "      <td>427975.00</td>\n",
       "      <td>7861300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>29570.00</td>\n",
       "      <td>303400.40</td>\n",
       "      <td>1085088.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>379000.00</td>\n",
       "      <td>58800000.00</td>\n",
       "      <td>29570.00</td>\n",
       "      <td>364300.06</td>\n",
       "      <td>393939.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>133500.00</td>\n",
       "      <td>243900.00</td>\n",
       "      <td>467500.00</td>\n",
       "      <td>11350000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>28645.00</td>\n",
       "      <td>363893.16</td>\n",
       "      <td>2274967.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>193000.00</td>\n",
       "      <td>435000.00</td>\n",
       "      <td>126940000.00</td>\n",
       "      <td>28645.00</td>\n",
       "      <td>422773.73</td>\n",
       "      <td>432387.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173100.00</td>\n",
       "      <td>303700.00</td>\n",
       "      <td>529900.00</td>\n",
       "      <td>15000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>33033.00</td>\n",
       "      <td>530580.09</td>\n",
       "      <td>1934406.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>537500.00</td>\n",
       "      <td>231058000.00</td>\n",
       "      <td>33033.00</td>\n",
       "      <td>478192.98</td>\n",
       "      <td>476555.17</td>\n",
       "      <td>800.00</td>\n",
       "      <td>205000.00</td>\n",
       "      <td>342600.00</td>\n",
       "      <td>587500.00</td>\n",
       "      <td>9966300.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SALES PRICE                                                          \\\n",
       "            count      mean        std  min       25%       50%       75%   \n",
       "TAXYR                                                                       \n",
       "2011     26777.00 162950.94  630129.89 0.00      0.00  56050.00 189900.00   \n",
       "2012     22684.00 164550.67  424239.44 0.00      0.00  49500.00 200515.00   \n",
       "2013     26074.00 166081.78  440832.36 0.00      0.00  47000.00 212000.00   \n",
       "2014     11711.00 331640.54  351925.01 0.00  79000.00 255000.00 455000.00   \n",
       "2015     11256.00 357182.81  392959.23 0.00 101425.00 275000.00 475000.00   \n",
       "2016     14978.00 348266.13  401923.49 0.00  85000.00 258325.00 474500.00   \n",
       "2017     13210.00 386344.64  386724.40 0.00 139000.00 294000.00 517500.00   \n",
       "2018     28281.00 268587.37  931256.97 0.00      1.00 108000.00 360000.00   \n",
       "2019     29134.00 522038.36 2227323.74 0.00      1.00 137000.00 379900.00   \n",
       "2020     29570.00 303400.40 1085088.76 0.00      1.00 155000.00 379000.00   \n",
       "2021     28645.00 363893.16 2274967.99 0.00      1.00 193000.00 435000.00   \n",
       "2022     33033.00 530580.09 1934406.18 0.00     10.00 250000.00 537500.00   \n",
       "\n",
       "                   FAIR MARKET VALUE                                        \\\n",
       "               max             count      mean       std     min       25%   \n",
       "TAXYR                                                                        \n",
       "2011   51718108.00          26777.00 210525.70 292278.99    0.00  42100.00   \n",
       "2012   20500000.00          22684.00 241854.35 325947.29 1500.00  56600.00   \n",
       "2013   17038094.00          26074.00 238072.86 323868.49    0.00  39500.00   \n",
       "2014    6350000.00          11711.00 294653.60 320690.06  100.00  63900.00   \n",
       "2015   13914719.00          11256.00 314046.58 324030.38 1390.00  74887.50   \n",
       "2016   17455046.00          14978.00 346104.72 368631.02    0.00  91500.00   \n",
       "2017    7200000.00          13210.00 306637.00 320307.43    0.00  75725.00   \n",
       "2018  135635876.00          28281.00 307217.92 359431.09    0.00  75800.00   \n",
       "2019   40120000.00          29134.00 328591.65 367677.75  100.00 107200.00   \n",
       "2020   58800000.00          29570.00 364300.06 393939.77    0.00 133500.00   \n",
       "2021  126940000.00          28645.00 422773.73 432387.60    0.00 173100.00   \n",
       "2022  231058000.00          33033.00 478192.98 476555.17  800.00 205000.00   \n",
       "\n",
       "                                       \n",
       "            50%       75%         max  \n",
       "TAXYR                                  \n",
       "2011  115300.00 276200.00  8750000.00  \n",
       "2012  142800.00 314800.00 13698600.00  \n",
       "2013  142225.00 325900.00  6322800.00  \n",
       "2014  226960.00 402150.00  6189700.00  \n",
       "2015  244970.00 428770.00  6151600.00  \n",
       "2016  257500.00 470000.00  6000000.00  \n",
       "2017  225900.00 425000.00  6000000.00  \n",
       "2018  198500.00 418000.00  7150000.00  \n",
       "2019  207000.00 427975.00  7861300.00  \n",
       "2020  243900.00 467500.00 11350000.00  \n",
       "2021  303700.00 529900.00 15000000.00  \n",
       "2022  342600.00 587500.00  9966300.00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_full.groupby(\"TAXYR\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV, Parquet\n",
    "OUTPUT_PATH = 'output/fulton_sales_all'\n",
    "sales_full.to_csv(OUTPUT_PATH + '.csv', index=False)\n",
    "sales_full.to_parquet(OUTPUT_PATH + '.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocode digest data and determine NSA of each parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parcels unable to be matched: 6819\n"
     ]
    }
   ],
   "source": [
    "# Join all years digest to 2022 Fulton County geocoded parcel boundaries on ParcelID; e.g. geocode parcels\n",
    "# Record # parcels not matched (ones that changed over the years, so now have a different ParcelID)\n",
    "geo_parcels = gpd.read_file(\"./data/fulton_parcels.geojson\")\n",
    "geo_parcels = geo_parcels[[\"ParcelID\", \"OBJECTID\", \"geometry\"]]\n",
    "geo_parcels = geo_parcels.rename(columns={\"ParcelID\": \"PARID\"})\n",
    "\n",
    "# DF of parcels with associated geometry\n",
    "digest_full_geo = geo_parcels.merge(digest_full, on=\"PARID\", how=\"inner\")\n",
    "print(f\"Number of parcels unable to be matched: {len(digest_full) - len(digest_full_geo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate CRS: True\n"
     ]
    }
   ],
   "source": [
    "# Create a DF of ATL NSA statistics from 2021 5 year ACS estimates (aquired from Neighborhood Nexus), use later for analysis\n",
    "# Spatially join parcel geodata to Atlanta NSAs to get the neighborhood of each parcel\n",
    "atl_nsa_stats = pd.read_csv(\"./data/atl_nsa_stats.csv\")\n",
    "atl_nsa_stats = atl_nsa_stats.rename(columns={\"Details\": \"neighborhood\"})\n",
    "\n",
    "geo_atl_nsa = gpd.read_file(\"./data/atl_nsa.geojson\")\n",
    "geo_atl_nsa = geo_atl_nsa.rename(columns={\"NEIGHBORHO\": \"neighborhood\"})\n",
    "geo_atl_nsa = geo_atl_nsa[[\"neighborhood\", \"geometry\"]]\n",
    "\n",
    "print(f\"Validate CRS: {digest_full_geo.crs == geo_atl_nsa.crs}\")\n",
    "\n",
    "# DF with ATL NSA geometries and ACS statistics\n",
    "# geo_atl_nsa = geo_atl_nsa.merge(atl_nsa_stats, on=\"neighborhood\", how=\"inner\")\n",
    "\n",
    "# DF with all Fulton parcels and their matched neighborhood (some may not have a match)\n",
    "digest_full_geo_nbhd = digest_full_geo.sjoin(geo_atl_nsa, how='left', predicate='within').drop(columns=\"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched parcels in ATL: 1009001\n"
     ]
    }
   ],
   "source": [
    "# Drop NSAs from Atlanta NSA df which has no matches (e.g. those outside of Fulton County) - tho we want to retain all Fulton for comparison\n",
    "# Write the NSAs we include and those we don't to a text file for Appendix\n",
    "digest_atl_geo_nbhd = digest_full_geo_nbhd[digest_full_geo_nbhd['neighborhood'].notna()]\n",
    "print(f\"Number of matched parcels in ATL: {len(digest_atl_geo_nbhd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\556227967.py:2: UserWarning: Geometry column does not contain geometry.\n",
      "  digest_full_geo_nbhd[\"geometry\"] = digest_full_geo_nbhd[\"geometry\"].astype(\"string\")\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6400\\556227967.py:3: UserWarning: Geometry column does not contain geometry.\n",
      "  digest_atl_geo_nbhd[\"geometry\"] = digest_atl_geo_nbhd[\"geometry\"].astype(\"string\")\n",
      "c:\\Users\\Nick\\Documents\\code\\equity-extraction\\equity-extraction\\Lib\\site-packages\\geopandas\\geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Cast geometry column to string for Parquet\n",
    "digest_full_geo_nbhd[\"geometry\"] = digest_full_geo_nbhd[\"geometry\"].astype(\"string\")\n",
    "digest_atl_geo_nbhd[\"geometry\"] = digest_atl_geo_nbhd[\"geometry\"].astype(\"string\")\n",
    "\n",
    "# Output intermediary data for analysis\n",
    "OUTPUT_PATH = './output/'\n",
    "\n",
    "digest_full_geo_nbhd.to_csv(OUTPUT_PATH + 'digest_full_geo_nbhd.csv', index=False)\n",
    "digest_full_geo_nbhd.to_parquet(OUTPUT_PATH + 'digest_full_geo_nbhd.parquet')\n",
    "\n",
    "digest_atl_geo_nbhd.to_csv(OUTPUT_PATH + 'digest_atl_geo_nbhd.csv', index=False)\n",
    "digest_atl_geo_nbhd.to_parquet(OUTPUT_PATH + 'digest_atl_geo_nbhd.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equity-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
